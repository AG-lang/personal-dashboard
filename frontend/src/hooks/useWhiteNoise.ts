import { useState, useRef, useCallback } from 'react'

interface WhiteNoiseTrack {
  id: string
  name: string
  url: string
  icon: string
}

// å†…ç½®ç™½å™ªéŸ³é€‰é¡¹
export const WHITE_NOISE_TRACKS: WhiteNoiseTrack[] = [
  {
    id: 'none',
    name: 'æ— ',
    url: '',
    icon: 'ðŸ”‡'
  },
  {
    id: 'rain',
    name: 'é›¨å£°',
    url: '/sounds/rain.mp3',
    icon: 'ðŸŒ§ï¸'
  },
  {
    id: 'forest',
    name: 'æ£®æž—',
    url: '/sounds/forest.mp3',
    icon: 'ðŸŒ²'
  },
  {
    id: 'ocean',
    name: 'æµ·æµª',
    url: '/sounds/ocean.mp3',
    icon: 'ðŸŒŠ'
  },
  {
    id: 'cafe',
    name: 'å’–å•¡åŽ…',
    url: '/sounds/cafe.mp3',
    icon: 'â˜•'
  },
  {
    id: 'chimes',
    name: 'é£Žé“ƒ',
    url: '/sounds/mixkit-wind-chimes-2014.wav',
    icon: 'ðŸŽ'
  }
]

// Web Audio API ç™½å™ªéŸ³ç”Ÿæˆå™¨
const generateWhiteNoise = () => {
  try {
    const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)()
    const bufferSize = 2 * audioContext.sampleRate
    const noiseBuffer = audioContext.createBuffer(1, bufferSize, audioContext.sampleRate)
    const output = noiseBuffer.getChannelData(0)
    
    for (let i = 0; i < bufferSize; i++) {
      output[i] = Math.random() * 2 - 1
    }
    
    const whiteNoise = audioContext.createBufferSource()
    whiteNoise.buffer = noiseBuffer
    whiteNoise.loop = true
    
    const gainNode = audioContext.createGain()
    whiteNoise.connect(gainNode)
    gainNode.connect(audioContext.destination)
    
    return { source: whiteNoise, gain: gainNode, context: audioContext }
  } catch (error) {
    console.error('ç”Ÿæˆç™½å™ªéŸ³å¤±è´¥:', error)
    return null
  }
}

export function useWhiteNoise() {
  const [currentTrack, setCurrentTrack] = useState<WhiteNoiseTrack>(WHITE_NOISE_TRACKS[0])
  const [isPlaying, setIsPlaying] = useState(false)
  const [volume, setVolume] = useState(0.5)
  const audioRef = useRef<HTMLAudioElement | null>(null)

  // æ’­æ”¾æŒ‡å®šéŸ³è½¨
  const playTrack = useCallback(async (track: WhiteNoiseTrack) => {
    try {
      // åœæ­¢å½“å‰æ’­æ”¾
      if (audioRef.current) {
        audioRef.current.pause()
        audioRef.current = null
      }

      setCurrentTrack(track)

      if (track.id === 'none' || !track.url) {
        setIsPlaying(false)
        return
      }

      // åˆ›å»ºæ–°çš„éŸ³é¢‘å¯¹è±¡
      const audio = new Audio(track.url)
      audio.volume = volume
      audio.loop = true

      audioRef.current = audio

      // æ’­æ”¾éŸ³é¢‘
      await audio.play()
      setIsPlaying(true)
    } catch (error) {
      console.error('æ’­æ”¾ç™½å™ªéŸ³å¤±è´¥:', error)
      setIsPlaying(false)
    }
  }, [volume])

  // åœæ­¢æ’­æ”¾
  const stop = useCallback(() => {
    if (audioRef.current) {
      audioRef.current.pause()
      audioRef.current = null
    }
    setIsPlaying(false)
  }, [])

  // åˆ‡æ¢æ’­æ”¾/æš‚åœ
  const toggle = useCallback(async () => {
    if (isPlaying) {
      stop()
    } else {
      await playTrack(currentTrack)
    }
  }, [isPlaying, currentTrack, playTrack, stop])

  // è°ƒæ•´éŸ³é‡
  const changeVolume = useCallback((newVolume: number) => {
    const clampedVolume = Math.max(0, Math.min(1, newVolume))
    setVolume(clampedVolume)
    
    if (audioRef.current) {
      audioRef.current.volume = clampedVolume
    }
  }, [])

  // é€‰æ‹©éŸ³è½¨
  const selectTrack = useCallback(async (trackId: string) => {
    const track = WHITE_NOISE_TRACKS.find(t => t.id === trackId)
    if (track) {
      await playTrack(track)
    }
  }, [playTrack])

  return {
    currentTrack,
    isPlaying,
    volume,
    tracks: WHITE_NOISE_TRACKS,
    playTrack,
    stop,
    toggle,
    changeVolume,
    selectTrack
  }
}